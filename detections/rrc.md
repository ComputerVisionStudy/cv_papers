Accurate Single Stage Detector Using Recurrent Rolling Convolution
=

# 1 贡献：
1. 本文表明端到端的训练一阶段检测可以产生任务需要的高定位质量的准确检测结果。
2. 本文发现改善一阶段检测器的关键是递归地将上下文引入边界框回归。这一过程可以有所提出的Recurrent Rolling Convolution架构有效地实现。

# 2 Analysis and Our Approach
## 2.1 The Missing Piece of The Current Methods
强大的物体检测系统必须能够同时检测具有截然不同的尺度和纵横比的对象。在Faster R-CNN [16]中，它依赖于最后一个卷积层的每个重叠 $3 \times 3$ 区域的大的感受野来检测小对象和大对象。因为使用了多个池化层，所以最后一个层的特征图远小于输入图像。这可能对于检测小对象是一个问题，因为在低分辨率特征图中，表示小对象的精细细节的特征可能很弱。

在CNN中，由于池化层的存在，随着网络的深入，特征图的分辨率递减形成金字塔形状。SSD便利用这个事实，在不同分辨率的特征图上检测对象。这种方法的优点在于它不仅通过将这些对象的分类和边界框回归重新定位到更高分辨率的层，提供了更准确地定位小对象的机会，因为单阶段方法它也比以前的 两阶段方法快得多。因为这种多尺度处理不会给原始骨干网络增加额外的计算。

然而，SSD无法超越最先进的两阶段方法。**实际上，当使用高IoU阈值评估时，这种差距更加明显。** 接下来分析和讨论为何这是SSD的局限。同时也表明如何使用所提出的一阶段模型处理这种局限，并获得最先进结果。SSD中的多尺度特征图实现可以表示为：
$$
\begin{align}
\Phi_n = f_n(\Phi_{n-1}) = f_n(f_{n-1}(...f1(I)))  \tag 1 \\
Detection = \cal{D}(\tau_n(\Phi_n), ..., \tau_{n-k}(\Phi_{n-k})), n > k > 0 \tag 2
\end{align}
$$
其中 $\Phi_n$ 是第 $n$ 层的特诊图， $f_n(\cdot)$ 将第 $n-1$ 层特征图变换到第 $n$ 层的非线性函数。$f_n(\cdot)$ 可以是卷积层、池化层、ReLU等的组合。 $\tau_n(\cdot)$ 是将第 $n$ 层特征图转换到某个特定尺度范围的检测结果的函数。$\cal{D}$ 是聚合所有中间结果并生成最终检测的最终操作。

根据方程（2），可以发现它表现良好在很大程度上依赖于强有力的假设。因为每层特征图仅对它尺度的输出负责，所以假设每个 $\Phi$ 本身必须足够复杂以支持感兴趣对象的检测和准确定位。这种复杂意味着 **1）特征图应当具有足够的分辨率来表示精细的对象细节；2）将输入图像转换到特征图的函数应当足够深，使得对象丰富的高层抽象能够在特诊图中构建；3）特征图包含适当的上下文信息，基于该信息可以可靠地推断重叠对象、被遮挡对象、小对象、模糊或饱和对象的精确位置[16,12,18]。** 由式（1）和（2）知， 当 $k$ 很大时， $\Phi_n$ 远深于 $\Phi_{n-k}$ ，因此前面提到的第二个条件在 $Phi_{n-k}$ 中不满足。结果是 $\tau_{n-k}(\cdot)$ （将第 $n-k$ 层的特征图转换到检测输出的函数）可能更加弱，并且比 $\Phi_n$ 更难训练。Faster R-CNN并不存在这种深度问题，因为他的区域提议在最后层的特征图生成，即：
$$Region proposals = \cal{R}(\tau_n(\Phi_n)), n > 0  \tag 3$$
然而，式（3）不满足第一个条件。因此，本文认为在单级检测器中学习的更合理的函数可以定义如下：
$$
\begin{align}
Detection = \hat{\cal{D}}(\tau_n(\hat{\Phi}_n(\cal{H})), \tau_{n-1}(\hat{\Phi}_{n-1}(\cal{H})),  \\
\cdots, \tau_{n-k}(\hat{\Phi}_{n-k}(\cal{H})))  \\
\cal{H} = \{\Phi_n, \Phi_{n-1}, \cdots, \Phi_{n-k}\}, n>k>0,  \\
size(\Phi_{n-k}) = size(\hat{\Phi_{n-k}}(\cal{H})), \forall k
\end{align}  \tag 4
$$
其中 $\cal{H}$ 是包含用于检测函数 $\cal{D}(\cdots)$ 的所有特征图的集合。不同于式（2），$\hat{\Phi}_n(\cdot)$ 现在是一个函数，其中考虑了所有贡献特征图，并将相同维度的新特征表示输出到 $\Phi_n$ 。

因为 $\hat{\Phi}_{n-k}$ 输出的特征图不仅共享与 $\Phi_{n-k}$ 相同的分辨率，而且处理更深层提取的特征，所以特征图复杂度的前两个条件是满足的。值得注意的是，尽管对方程（2）的修改， $D(\cdot)$ 仍然是单阶段过程。换句话说，如果式（4）满足第三个条件，并设计一个有效的架构训练它，将能够全面克服先前单阶段方法的局限性，并且即使对于高IoU阈值也有机会超越两阶段方法。

## 2.2 Recurrent Rolling Convolution
**RNN for Conditional Feature Aggregation** $\hat{\Phi}(\cdot)$ 张的纹理信息对于不同的对象有不同的含义。例如当检测小对象时，意味着 $\hat{\Phi}(\cdot)$ 应当返回包含该对象的更高分辨率特征的特征图，以表示缺失的信息。当检测遮挡对象时， $\hat{\Phi}(\cdot)$ 应当返回包含如此对象鲁棒性抽象的特征图，使得该特征对遮挡相应不变。当检测重叠对象时，$\hat{\Phi}(\cdot)$应当返回包含边界细节和高层收敛的特征图，以区分不同的对象。然而，对于中间层的特征图（如 $\Phi_p$，其中 $p$ 是正整数），所有上述上下文信息可以从其较低级别对应物 $\Phi_{p-q}$ 或其较高级别对应物 $\Phi_{p+r}$ 中检索，其中 $q$ 和 $r$ 也是正整数。难点在于，很难手工定义用于函数 $\hat{\Phi}_p(\cal{H})$ 的规则来检索合适的来自 $\Phi_{p-q}$ 和 $\Phi_{p+r}$ 的特征，也很难手工选择 $q$ 和 $r$ 。因此，必须从数据中，系统地学习这种特征检索和聚合。

然而， $\hat{\Phi}_p(\cal{H})$ 的学习可能很麻烦，因为 $\cal{H}$ 是一个包含不同层和不同尺度的多个特征图的集合，我们不知道应该涉及哪个特征图以及应该对特征图施加什么样的操作。因此，直接共 $\cal{H}$ 到可用的 $\hat{\Phi}_p(\cal{H})$ 映射必须求助于具有多层非线性的相当大的深度网络。这不会使得计算有效以及容易训练的单阶段网络。替代方法是设计一种迭代过程，该过程每个步骤是一个很小但有意义和一致的过程。这个过程能够使用如下的数学描述：
$$
\hat{\Phi}_p^{t+1} = \cal F(\hat{\Phi}_p^t, \hat{\Phi}_{p-1}^t, \hat{\Phi}_{p+1}^t), t > 0,  \\
\hat{\Phi}_p^t = \Phi_n, \forall n \mbox{ when } t=1  \tag 5
$$
其中 $\cal{F}$ 是将  在步骤 $t$ 中将 $\hat{\Phi}_p^t$ 及其直接的较高和较低级别的对应物映射到步骤 $t + 1$ 的新 $\hat{\Phi}_p$。函数 $\cal{F}$ 被可训练的权重 $\cal{W}$ 参数化。
